{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bc8fc00",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a664a2e4",
   "metadata": {},
   "source": [
    "Web scraping is a process for extracting the data from the website available on the internet.\n",
    "While working on any project we get data from client but some time we need to collect the data by ourself. \n",
    "for example if we have a data on certain webasite in that case we extrat the data from the website.\n",
    "so, to extract the data from the website we will going to use web scraping.\n",
    "\n",
    "Three areas where web scraping is used :\n",
    "    1) E-commerce website\n",
    "    2) Blog website\n",
    "    3) Financial Data extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d08b964",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9746590",
   "metadata": {},
   "source": [
    "There are various methods and tools for web scraping, ranging from simple manual techniques to more automated approaches.\n",
    "\n",
    "HTML Parsing: Web pages are written in HTML (Hypertext Markup Language). Parsing the HTML code of a webpage allows the\n",
    "extraction of specific elements, such as text, links, and images. Libraries like BeautifulSoup for Python are popular for\n",
    "HTML parsing.\n",
    "\n",
    "Regular Expressions: Regular expressions (regex) can be used to match and extract specific patterns from the raw HTML content.\n",
    "    \n",
    "Web Scraping Frameworks and Libraries: There are several programming languages and frameworks that provide built-in or \n",
    "third-party libraries for web scraping.\n",
    "\n",
    "for example : Python with BeautifulSoup\n",
    "    \n",
    "APIs (Application Programming Interfaces): Some websites provide APIs that allow developers to access and retrieve data in \n",
    "a structured format. Using APIs is generally more reliable and legal than web scraping, but not all websites offer APIs, \n",
    "and they may come with usage restrictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad51f149",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fd12c8",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library used for web scraping purposes to pull the data out of HTML and XML files. \n",
    "It provides Pythonic idioms for iterating, searching, and modifying the parse tree, making it easy to extract and \n",
    "manipulate data from HTML or XML documents.\n",
    "\n",
    "Beautiful Soup is commonly used for web scraping tasks. It simplifies the extraction of data from HTML and XML documents, \n",
    "enabling developers to focus on the specific elements they need rather than dealing with the complexities of parsing raw HTML.\n",
    "It facilitates the extraction of relevant information from web pages, making it easier to analyze and use the extracted data \n",
    "for various purposes, such as research, data mining, or creating datasets for machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b02d66",
   "metadata": {},
   "source": [
    "Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a9af26",
   "metadata": {},
   "source": [
    "Flask is known for its lightweight and minimalistic design, making it easy to set up and get started. Flask provides a \n",
    "straightforward mechanism for defining routes and handling URLs. This is crucial in a web scraping project where different\n",
    "parts of the application need to respond to specific URLs. Flask integrates with the Jinja2 template engine, enabling the \n",
    "dynamic rendering of HTML pages. This is beneficial for presenting scraped data in a user-friendly and customizable format. \n",
    "Web scraping often involves making HTTP requests to retrieve data from websites. Flask, being a web framework, naturally \n",
    "handles HTTP requests and responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f729c1d",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b98b555",
   "metadata": {},
   "source": [
    "The AWS service used in this project is Code-pipeline and BeanStalk.\n",
    "\n",
    "In this project the code is first pushed through GitHub from their it goes to Code-pipeline. So, a pipeline is created here\n",
    "to inject the data from GitHub to the Code-pipeline. After this a service called as BeanStalk is connected to the Code-pipeline\n",
    "BeanStalk provide various resources like memory, enviroment, system etc. BeanStalk help use to create a Appication which will\n",
    "be used for the scraping globaly after deployment. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
