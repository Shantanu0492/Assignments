{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44d0b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how\n",
    "can they be mitigated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6320f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Overfitting: Overfitting occurs when a machine learning model learns the training data too well, capturing noise or random \n",
    "fluctuations rather than the underlying pattern. This leads to poor generalization on new, unseen data. Consequences include\n",
    "a model that performs well on the training set but poorly on the test set. To mitigate overfitting, techniques like \n",
    "regularization, cross-validation, and using more data can be applied.\n",
    "\n",
    "Underfitting: Underfitting happens when a model is too simple to capture the underlying structure of the data, resulting \n",
    "in poor performance on both the training and test sets. It may occur when the model is too basic for the complexity of the\n",
    "data. Increasing model complexity, adding features, or choosing a more sophisticated algorithm can mitigate underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da34fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2: How can we reduce overfitting? Explain in brief."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7034b88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Use more training data to expose the model to a diverse set of examples.\n",
    "Apply regularization techniques, such as L1 or L2 regularization, to penalize overly complex models.\n",
    "Use cross-validation to assess model performance on different subsets of the data.\n",
    "Simplify the model architecture by reducing the number of parameters or features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc7b788",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3: Explain underfitting. List scenarios where underfitting can occur in ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d53fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Underfitting: Underfitting occurs when a model is too simple to capture the underlying patterns in the data. \n",
    "It can happen in scenarios where the model complexity is insufficient, the chosen algorithm is too basic, or\n",
    "the features used are not representative of the underlying relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7341cc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and\n",
    "variance, and how do they affect model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56035790",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bias-Variance Tradeoff: The bias-variance tradeoff represents a balance between bias (error due to overly simplistic \n",
    "assumptions) and variance (error due to model sensitivity to variations in the training data). High bias models tend \n",
    "to underfit, while high variance models tend to overfit. Achieving an optimal tradeoff results in a well-generalizing \n",
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1178bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models.\n",
    "How can you determine whether your model is overfitting or underfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d3c867",
   "metadata": {},
   "outputs": [],
   "source": [
    "Detecting Overfitting\n",
    "\n",
    "Monitoring performance on a separate validation set.\n",
    "Observing a significant performance gap between training and validation sets.\n",
    "Analyzing learning curves, looking for divergence between training and validation errors.\n",
    "\n",
    "Detecting Underfitting:\n",
    "\n",
    "Poor performance on both training and validation sets.\n",
    "Learning curves show slow convergence and persistently high errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1335127d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias\n",
    "and high variance models, and how do they differ in terms of their performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbcc284",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bias: High bias models (underfitting) make overly simplistic assumptions, leading to poor performance on both training \n",
    "and test sets. Example: Linear regression applied to a highly non-linear dataset.\n",
    "\n",
    "Variance: High variance models (overfitting) are sensitive to variations in the training data, performing well on training \n",
    "data but poorly on the test set. Example: A high-degree polynomial regression on a dataset with limited samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a7213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe\n",
    "some common regularization techniques and how they work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab298d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "Regularization: Regularization is a technique used to prevent overfitting by adding a penalty term to the cost function, \n",
    "discouraging overly complex models. Common techniques include:\n",
    "    \n",
    "L1 Regularization (Lasso): Adds the absolute values of coefficients as a penalty.\n",
    "L2 Regularization (Ridge): Adds the squared values of coefficients as a penalty.\n",
    "    \n",
    "Elastic Net Regularization: A combination of L1 and L2 regularization.\n",
    "Regularization helps to shrink or eliminate irrelevant features, promoting a more generalized model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
